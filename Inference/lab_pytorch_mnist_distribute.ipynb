{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qwyEpQXGdHD"
      },
      "outputs": [],
      "source": [
        "# Reference\n",
        "# https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyTePgDixNNz"
      },
      "source": [
        "#Lab 1-2/3. Quantization-aware training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xL9ysBBg4FDt",
        "outputId": "b748cdb8-7588-45cf-d910-116638017aaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/drive')\n",
        "wdir = './'\n",
        "if os.path.exists(wdir) == False:\n",
        "  os.mkdir(wdir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gng1IxX3GNYU"
      },
      "outputs": [],
      "source": [
        "# %matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rNli4GbrGNYY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v02q5ZHtGNYY"
      },
      "source": [
        "**1. Load dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2WG0GA9U6G_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0604482-3db4-4804-ec97-fee3223cb98e",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 19.9MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 482kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.51MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 10.8MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20000, 3334]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5), (0.5))])\n",
        "\n",
        "batch_size = 3\n",
        "\n",
        "# Your code: load dataset\n",
        "trainset = torchvision.datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset,\n",
        "                                          batch_size = batch_size,\n",
        "                                          shuffle = True,\n",
        "                                          num_workers = 1)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root = './data',\n",
        "                                     train = False,\n",
        "                                     download = True,\n",
        "                                     transform = transform)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset,\n",
        "                                         batch_size = batch_size,\n",
        "                                         shuffle = False,\n",
        "                                         num_workers = 1)\n",
        "\n",
        "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')\n",
        "print([len(trainloader), len(testloader)])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print([len(trainloader), len(testloader)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCdR5nueDg0s",
        "outputId": "a26bd52d-0ccf-46da-858e-e33a29948293"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20000, 3334]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = trainset[0]\n",
        "image.shape, label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkH22iovEcoP",
        "outputId": "1186f724-1aa2-4e8c-bf31-8d243cfa9b6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 28, 28]), 5)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "Wjh-Za-ZGNYa",
        "outputId": "49517edd-812b-4801-c5c8-a108cce6d0b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 1, 28, 28])\n",
            "tensor([2, 9, 7])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2     9     7    \n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# Print Shape of the image\n",
        "print(f'{images.shape}')\n",
        "print(f'{labels}')\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcdJNvYRGNYa"
      },
      "source": [
        "##2. Define neural network**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4B2IMZc3zrx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-1. Quantization model"
      ],
      "metadata": {
        "id": "caa_VwhMdRXu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpQUFWhK2Txa"
      },
      "outputs": [],
      "source": [
        "from torch.autograd.function import InplaceFunction\n",
        "\n",
        "# Your code: quantization\n",
        "\n",
        "def clip(input, qbit):\n",
        "  max_value = 2. ** (qbit-1) -1.\n",
        "  min_value = -2. ** (qbit-1)\n",
        "  output = torch.clip(input, min_value, max_value)\n",
        "  return output\n",
        "\n",
        "class UniformQuantize(InplaceFunction):\n",
        "  @classmethod\n",
        "  def forward(cls, ctx, input, qbit):\n",
        "    # Get Min/Max value of tensor (Min- Max quantization)\n",
        "    min_value = float(input.min())\n",
        "    max_value = float(input.max())\n",
        "    abs_min_value = abs(min_value)\n",
        "    abs_max_value = abs(max_value)\n",
        "    # Get Max, Min condition\n",
        "    if(abs_max_value >= abs_min_value):\n",
        "      min_cond = -abs_max_value\n",
        "      max_cond = abs_max_value\n",
        "    else:\n",
        "      min_cond = -abs_min_value\n",
        "      max_cond = abs_min_value\n",
        "    # Get Scale that is fit with INT8\n",
        "    qmin = 0.\n",
        "    qmax = 2.**qbit - 1.\n",
        "    scale = (max_cond - min_cond) / (qmax - qmin)\n",
        "    # Divide by scale and make into integer(Real Quantize)\n",
        "    output = input / scale\n",
        "    output.floor_()\n",
        "    # Quantize and clip\n",
        "    output = clip(input = output, qbit = qbit)\n",
        "    # Dequantize\n",
        "    output.mul_(scale)\n",
        "    return output\n",
        "\n",
        "  @staticmethod\n",
        "  def backward(ctx, grad_output):\n",
        "    # Straight-Through Estimator\n",
        "    grad_input = grad_output\n",
        "    return grad_input, None, None, None, None, None, None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def quant_minmax(input, qbit):\n",
        "  return UniformQuantize().apply(input, qbit)\n",
        "\n",
        "class QLinear(nn.Linear):\n",
        "  def __init__(self, in_features, out_features, bias = False, quantize = False, bita = 8, bitw = 8):\n",
        "    super().__init__(in_features, out_features, bias = bias)\n",
        "    self.in_features = in_features\n",
        "    self.out_features = out_features\n",
        "    self._bias = bias\n",
        "\n",
        "    self.quantize = quantize\n",
        "    self.bita = bita\n",
        "    self.bitw = bitw\n",
        "\n",
        "  def forward(self, input):\n",
        "    if self.quantize:\n",
        "      Qinput = quant_minmax(input, qbit = self.bita)\n",
        "      Qweight = quant_minmax(self.weight, qbit = self.bitw)\n",
        "    else:\n",
        "      Qinput = input\n",
        "      Qweight = self.weight\n",
        "    if self._bias:\n",
        "      return F.linear(input = Qinput, weight = Qweight, bias = self.bias)\n",
        "    else:\n",
        "      return F.linear(input = Qinput, weight = Qweight, bias = None)"
      ],
      "metadata": {
        "id": "nlx000fIeQ6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-2. Quantization Model(2)"
      ],
      "metadata": {
        "id": "q-YGFkwddpqy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXu0U2Tk34eI"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    # Your code: define neural network\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layer_stack = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            QLinear(28 * 28, 128, bias = False, quantize = True, bita = 8, bitw = 8),\n",
        "            nn.ReLU(),\n",
        "            QLinear(128, 10, bias = False, quantize = True, bita = 8, bitw = 8)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.layer_stack(x)\n",
        "      return x\n",
        "\n",
        "net = Net()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfKUGOUxGNYb"
      },
      "source": [
        "##3. Define loss function and optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbyyEZaVGNYb"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Your code: define loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3_5IUm_GNYc"
      },
      "source": [
        "##4. Set GPU**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SroNxi9GIkB2",
        "outputId": "7f444456-02b5-4e1e-92d1-a434c93264f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "Net(\n",
            "  (layer_stack): Sequential(\n",
            "    (0): Flatten(start_dim=1, end_dim=-1)\n",
            "    (1): QLinear(in_features=784, out_features=128, bias=False)\n",
            "    (2): ReLU()\n",
            "    (3): QLinear(in_features=128, out_features=10, bias=False)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Your code: Set GPU(Device agnostic code)\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)\n",
        "\n",
        "net.to(device)\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-LGiq8f1BrJ"
      },
      "source": [
        "##5. Train neural network**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2TGMZ6EGNYc",
        "outputId": "7c0a622f-76f4-4cd4-cdbc-fa82239845b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "-----\n",
            "[1,  2000], loss : 0.684\n",
            "[1,  4000], loss : 0.403\n",
            "[1,  6000], loss : 0.334\n",
            "[1,  8000], loss : 0.279\n",
            "[1,  10000], loss : 0.255\n",
            "[1,  12000], loss : 0.258\n",
            "[1,  14000], loss : 0.217\n",
            "[1,  16000], loss : 0.223\n",
            "[1,  18000], loss : 0.199\n",
            "[1,  20000], loss : 0.199\n",
            "Epoch: 1\n",
            "-----\n",
            "[2,  2000], loss : 0.161\n",
            "[2,  4000], loss : 0.164\n",
            "[2,  6000], loss : 0.169\n",
            "[2,  8000], loss : 0.146\n",
            "[2,  10000], loss : 0.151\n",
            "[2,  12000], loss : 0.156\n",
            "[2,  14000], loss : 0.163\n",
            "[2,  16000], loss : 0.153\n",
            "[2,  18000], loss : 0.133\n",
            "[2,  20000], loss : 0.131\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "# Your code: Train neural network\n",
        "\n",
        "# Set the number of epochs\n",
        "epochs = 2\n",
        "\n",
        "for epoch in range(epochs): # Loop over the dataset multiple times\n",
        "  print(f\"Epoch: {epoch}\\n-----\")\n",
        "  ### Training\n",
        "  train_loss = 0\n",
        "\n",
        "  # Set Train Mode\n",
        "  net.train()\n",
        "\n",
        "  # Add a loop to loop through the training batches\n",
        "  for batch, (X, y) in enumerate(trainloader):\n",
        "\n",
        "    # Put data on target device\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    # 1. Forward pass\n",
        "    y_pred = net(X)\n",
        "\n",
        "    # 2. Calculate loss (per batch)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss # accumulate train_loss\n",
        "\n",
        "    #3. Optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    #4. Loss backward\n",
        "    loss.backward()\n",
        "\n",
        "    #5. Optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 2000 == 1999: # Print out every 2000 mini-batches\n",
        "      print(f'[{epoch + 1}, {batch + 1 : 5d}], loss : {train_loss / 2000 :.3f}')\n",
        "      train_loss = 0\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0zDfsIWGNYc"
      },
      "source": [
        "##6. Save trained model and test accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7o2iE-d9GNYc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf12bd6a-a6ba-4bb6-bd63-6f57b51f7899"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to: models/mnist_net.pth\n"
          ]
        }
      ],
      "source": [
        "# Your code: Save trained model\n",
        "from pathlib import Path\n",
        "\n",
        "# Create model directory path\n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Create model file path\n",
        "MODEL_NAME = \"mnist_net.pth\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "# Save the model state dict\n",
        "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
        "torch.save(obj = net.state_dict(),\n",
        "           f = MODEL_SAVE_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_fn(y_true, y_pred):\n",
        "  accuracy = torch.eq(y_true, y_pred).sum().item() / len(y_true)\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "SEoFNqqXT5wY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHyYwf1JGNYe",
        "outputId": "9a3db0ad-7118-4365-ba45-7cff00b94e8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.13058, Test Acc: 0.96\n"
          ]
        }
      ],
      "source": [
        "# Your code: Test accuracy\n",
        "test_loss, test_acc = 0.0, 0.0\n",
        "net.eval()\n",
        "with torch.inference_mode():\n",
        "  for X_test, y_test in testloader:\n",
        "    X_test, y_test = X_test.to(device), y_test.to(device)\n",
        "\n",
        "    #1. Forward Pass\n",
        "    test_pred = net(X_test)\n",
        "\n",
        "    #2. Calculate Loss\n",
        "    test_loss += loss_fn(test_pred, y_test)\n",
        "\n",
        "    #3. Calculate Accuracy\n",
        "    test_acc += accuracy_fn(y_true = y_test, y_pred = test_pred.argmax(dim = 1))\n",
        "\n",
        "  # Calculate the test loss average per batch\n",
        "  test_loss /= len(testloader)\n",
        "\n",
        "  # Calculate the test accuracy average per batch\n",
        "  test_acc /= len(testloader)\n",
        "\n",
        "  # Print out what's happening\n",
        "  print(f\"Test Loss: {test_loss:.5f}, Test Acc: {test_acc:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z99LKiFOGNYd"
      },
      "source": [
        "## 7. Extract weights**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKewoOgp0yA2"
      },
      "outputs": [],
      "source": [
        "pt = torch.load(f = MODEL_SAVE_PATH)\n",
        "\n",
        "def clip(input, qbit):\n",
        "  max_value = 2. ** (qbit-1) -1.\n",
        "  min_value = -2. ** (qbit-1)\n",
        "  output = np.clip(input, min_value, max_value)\n",
        "  return output\n",
        "\n",
        "def uniform_quantize(input, qbit):\n",
        "  min_value = min(input)\n",
        "  max_value = max(input)\n",
        "  abs_min_value = abs(min_value)\n",
        "  abs_max_value = abs(max_value)\n",
        "  if (abs_max_value >= abs_min_value):\n",
        "    min_cond = -abs_max_value\n",
        "    max_cond = abs_max_value\n",
        "  else:\n",
        "    min_cond = -abs_min_value\n",
        "    max_cond = abs_min_value\n",
        "  qmin = 0\n",
        "  qmax = 2. ** qbit - 1.\n",
        "  scale = (max_cond - min_cond) / (qmax - qmin)\n",
        "  output = input / scale\n",
        "  output = np.floor(output)\n",
        "  output = clip(input=output, qbit=qbit)\n",
        "  return output, scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hu4hac-h0-7L",
        "outputId": "7d4800f3-8339-4a5b-e09e-d0c75ada0c3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 784])\n",
            "torch.Size([10, 128])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3286959665.py:24: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  output = np.floor(output)\n"
          ]
        }
      ],
      "source": [
        "# Your code: Extract weights\n",
        "global cnt_callextract\n",
        "cnt_callextract = 0\n",
        "\n",
        "for i, v in enumerate(pt.keys()):\n",
        "  fp = wdir + 'w' + str(cnt_callextract) + '.' + v + '.csv'\n",
        "  fp_scale = wdir + 'w' + str(cnt_callextract) + '.' + v + '_scale.csv'\n",
        "  print(pt[v].cpu().shape)\n",
        "  if v.find(\"num_batches_tracked\") == -1:\n",
        "    _w = pt[v].cpu()\n",
        "    if len(_w.shape) == 2:\n",
        "      _reshape = np.reshape(_w, (_w.shape[0] * _w.shape[1]))\n",
        "    elif len(_w.shape) == 1:\n",
        "      _reshape = np.reshape(_w, (_w.shape))\n",
        "    elif len(_w.shape) == 4:\n",
        "      _reshape = np.reshape(_w, (_w.shape[0] * _w.shape[1] * _w.shape[2] * _w.shape[3]))\n",
        "    else:\n",
        "      print(\"Unknown arch\")\n",
        "    _reshape_q, _scale_w = uniform_quantize(input = _reshape, qbit = 8)\n",
        "    np.savetxt(fp, _reshape_q, delimiter=',')\n",
        "    np.savetxt(fp_scale, [_scale_w], delimiter=',')\n",
        "    cnt_callextract += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-f6Cc3iu7Otj"
      },
      "outputs": [],
      "source": [
        "drive.flush_and_unmount()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCU0rMWYyHQq"
      },
      "source": [
        "# Lab 3/3. Verification of quantized model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aq4xXdju77w0",
        "outputId": "d5a57bec-0091-4153-89de-6880e520679d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /drive\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# import os\n",
        "# import numpy as np\n",
        "drive.mount('/drive')\n",
        "# wdir = '/drive/MyDrive/Colab Notebooks/tmpdata_npudesign_quant/'\n",
        "wdir = './'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.path.exists(wdir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ul6yOtQtVhBr",
        "outputId": "afc90bd7-3d07-4913-f7df-06b82eb155a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6j2DKOmAv_x7"
      },
      "outputs": [],
      "source": [
        "fp_w0 = wdir + 'w0.layer_stack.1.weight.csv'\n",
        "fp_w0_scale = wdir + 'w0.layer_stack.1.weight_scale.csv'\n",
        "\n",
        "np_w0 = np.loadtxt(fp_w0, delimiter=',', dtype=float)\n",
        "np_w0_scale = float(np.loadtxt(fp_w0_scale, delimiter=',', dtype=float))\n",
        "\n",
        "fp_w2 = wdir + 'w1.layer_stack.3.weight.csv'\n",
        "fp_w2_scale = wdir + 'w1.layer_stack.3.weight_scale.csv'\n",
        "\n",
        "np_w2 = np.loadtxt(fp_w2, delimiter=',', dtype=float)\n",
        "np_w2_scale = float(np.loadtxt(fp_w2_scale, delimiter=',', dtype=float))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np_w0.shape)"
      ],
      "metadata": {
        "id": "IUnWity3FZfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rewpC2629bg"
      },
      "source": [
        "### 1. Convert dataset (optional)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMRfGWeA374G",
        "outputId": "a40aa253-c23c-47e2-ba3c-2a7369bef82d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convert Finished!\n"
          ]
        }
      ],
      "source": [
        "# dataset-ubyte to csv\n",
        "def convert(imgf, labelf, outf, n):\n",
        "    f = open(imgf, \"rb\")\n",
        "    o = open(outf, \"w\")\n",
        "    l = open(labelf, \"rb\")\n",
        "\n",
        "    f.read(16)\n",
        "    l.read(8)\n",
        "    images = []\n",
        "\n",
        "    for i in range(n):\n",
        "        image = [ord(l.read(1))]\n",
        "        for j in range(28*28):\n",
        "            image.append(ord(f.read(1)))\n",
        "        images.append(image)\n",
        "\n",
        "    for image in images:\n",
        "        o.write(\",\".join(str(pix) for pix in image)+\"\\n\")\n",
        "    f.close()\n",
        "    o.close()\n",
        "    l.close()\n",
        "\n",
        "rawdir = \"/content/data/MNIST/raw/\"\n",
        "convertdir = wdir + \"mnist_test.csv\"\n",
        "if os.path.exists(convertdir) == False:\n",
        "  convert(rawdir + \"t10k-images-idx3-ubyte\", rawdir + \"t10k-labels-idx1-ubyte\",\n",
        "        wdir + \"mnist_test.csv\", 10000)\n",
        "  print(\"Convert Finished!\")\n",
        "else:\n",
        "  print(convertdir + \": exists\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xv4Q8wEpacf"
      },
      "outputs": [],
      "source": [
        "fp_input_csv = wdir + 'mnist_test.csv'\n",
        "np_input_csv = np.loadtxt(fp_input_csv, delimiter=',', dtype=float)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPLshSsV3OjY"
      },
      "source": [
        "### 2. Verify quantized weights**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np_w0[1 * 784 + 0 : 1 * 784 + 10])\n",
        "print(np_input_csv[50][500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4DInF8uXNJ_",
        "outputId": "f02216c7-1ebe-45af-e206-39c3bffcaa47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-3. 12. -6. 12. -1. -4. -7. -8. -4.  6.]\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZEqYOVwcYM_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "517423d4-3d93-4257-dcfe-d4a9df2afba1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inference: 7, answer: 7\n",
            "inference: 2, answer: 2\n",
            "inference: 1, answer: 1\n",
            "inference: 0, answer: 0\n",
            "inference: 4, answer: 4\n",
            "inference: 1, answer: 1\n",
            "inference: 4, answer: 4\n",
            "inference: 9, answer: 9\n",
            "inference: 6, answer: 5\n",
            "inference: 9, answer: 9\n"
          ]
        }
      ],
      "source": [
        "# Your code: Verify quantized weights\n",
        "\n",
        "testsize = 10\n",
        "\n",
        "for b in range(testsize):\n",
        "  _label = int(np_input_csv[b][0])\n",
        "  _image = np_input_csv[b][1:785]\n",
        "\n",
        "  # fc1\n",
        "  np_ia0_q, scale_ia0 = uniform_quantize(input=_image, qbit = 8)\n",
        "  np_oa0 = np.zeros([128], dtype = float)\n",
        "  for i in range(128):\n",
        "    for j in range(784):\n",
        "      np_oa0[i] += np_ia0_q[j] * np_w0[i * 784 + j]\n",
        "  np_oa0 *= scale_ia0 * np_w0_scale\n",
        "\n",
        "  # fc2\n",
        "  np_ia2 = np.empty([128], dtype = float)\n",
        "  for i in range(128):\n",
        "    np_ia2[i] = np_oa0[i] if np_oa0[i] > 0 else 0\n",
        "\n",
        "  np_ia2_q, scale_ia2 = uniform_quantize(input=np_ia2, qbit = 8)\n",
        "  np_oa2 = np.zeros([10], dtype = float)\n",
        "\n",
        "  for i in range(10):\n",
        "    for j in range(128):\n",
        "      np_oa2[i] += np_ia2_q[j] * np_w2[i * 128 + j]\n",
        "  np_oa2 *= scale_ia2 * np_w2_scale\n",
        "\n",
        "  #\n",
        "  _infer = np.argmax(np_oa2)\n",
        "  print(\"inference: \" + str(_infer) + \", answer: \" + str(_label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqVnenYH6iv9"
      },
      "outputs": [],
      "source": [
        "drive.flush_and_unmount()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# export small dataset version\n",
        "fp_input_small_csv = wdir + 'mnist_test_small.csv'\n",
        "np.savetxt(fp_input_small_csv, np_input_csv[0:10], delimiter=',')\n",
        "\n",
        "np_input_small_csv = np.loadtxt(fp_input_small_csv, delimiter=',', dtype=float)\n",
        "print(np_input_small_csv.shape)"
      ],
      "metadata": {
        "id": "ZCFOBE4yZCe0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64872832-4c2e-465c-8d49-e44cf7a40905"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 785)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.loadtxt(wdir + 'mnist_test.csv', delimiter=',', dtype=float)\n",
        "print(arr.shape)          # ✅ 정상: (10000, 785)  ❌ 비정상: (10000,), (1, 10000), (785, 10000) 등\n",
        "print(arr[:2, :10])       # 앞 2행 미리보기 (라벨+픽셀 일부)"
      ],
      "metadata": {
        "id": "nlXWbHPhdCp4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d73dbf0-b7ad-40da-c1e2-e1ee5b26c2fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 785)\n",
            "[[7. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [2. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full = np.loadtxt(wdir + 'mnist_test.csv', delimiter=',', dtype=float)\n",
        "print(\"full shape:\", full.shape)                 # → (10000, 785) 여야 정상\n",
        "\n",
        "pixels = full[:, 1:]\n",
        "print(\"pixels min/max:\", pixels.min(), pixels.max())  # → 0 ~ 255 사이\n",
        "print(\"nonzero count, first row:\", int(np.count_nonzero(pixels[0])))\n",
        "print(\"first row nonzero indices (first 15):\", np.where(pixels[0] > 0)[0][:15])\n"
      ],
      "metadata": {
        "id": "CnINAhx2dDAc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e279e30-85e2-4dd0-9711-0c88a036435c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "full shape: (10000, 785)\n",
            "pixels min/max: 0.0 255.0\n",
            "nonzero count, first row: 116\n",
            "first row nonzero indices (first 15): [202 203 204 205 206 207 230 231 232 233 234 235 236 237 238]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8kJfJFc2gzdu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}